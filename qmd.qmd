---
format: 
  pdf:
    fig-pos: "H"
    tbl-pos: "H"
lang: es
echo: FALSE
message: FALSE
warning: FALSE
fig-cap-location: top
geometry: 
- top= 25mm
- left= 20mm
- right = 20mm
- bottom = 25mm
---


::: {.center data-latex=""}

\vspace{3cm}

```{r logo facultad, echo=F, include = T, out.width= "60%"}
knitr::include_graphics("Imgs/unr.jpeg")
```

\pagenumbering{gobble}

\vspace{5cm}

\Large
**LICENCIATURA EN ESTADÍSTICA**

\vspace{1cm}

\Large
**Predicción de fraude financiero**


\vspace{0.3cm}
\large

*Un análisis mediante modelos lineales generalizados*

\vspace{9cm}

\large

**Autores: Franco Santini - Nicolas Gamboa - Andrés Roncaglia**

**Docentes: Boggio Gabriela - Harvey Guillermina - Costa Victorio**

**2024**
\normalsize
\newpage
\hypersetup{linkcolor = black}
\tableofcontents


\newpage
\pagenumbering{arabic}

:::

\newpage


# Introducción

El fraude con tarjetas de crédito es una de las principales amenazas que sufren los bancos. Con el auge de la tecnología las transacciones digitales facilitaron los traspasos de dinero y los medios de pago electrónicos son algo de cada día, pero junto con las ventajas también vinieron las consecuencias, y es que los métodos de fraude se han vuelto más sofisticados, generando pérdidas significativas a los bancos y afectando la confianza de los usuarios. Actividades como el uso no autorizado de tarjetas, la clonación de datos y transacciones fraudulentas requieren el desarrollo de tecnologías avanzadas para la detección temprana y la prevención.

# Variables:

- `fraud_bool`: Indicadora de si la transacción fue fraude o no

- `income`: Ingreso anual en cuantiles

- `name_email_similarity`: Similitud del nombre en el email y el nombre del solicitante

<!-- - `prev_address_months_count`: Es el número de meses que la persona estuvo viviendo en su locacion anterior -->

<!-- - `current_address_months_count`: Es el número de meses que la persona estuvo viviendo en su locación actual -->

- `customer_age`: Edad del cliente en décadas

- `days_since_request`: Días desde la solicitud

<!-- - `intended_balcon_amount`: Valor de la transferecia inicial para aplicar al crédito -->

- `payment_type`: Tipo del plan de pago 

<!-- - `zip_count_4w`: Número de aplicaciónes con el mismo código postal en las últimas 4 semanas -->

<!-- - `velocity_6h`: Es la velocidad del total de solicitudes de transferencias de la tarjeta en las últimas 6 horas -->

<!-- - `velocity_24h`: Es la velocidad del total de solicitudes de transferencias de la tarjeta en las últimas 24 horas -->

<!-- - `velocity_4w`: Es la velocidad del total de solicitudes de transferencias de la tarjeta en las últimas 4 semanas -->

<!-- - `bank_branch_count_8w`: Número total de solicitudes en la seleccionada rama del banco en las últimas 8 semanas -->

<!-- - `date_of_birth_distinct_emails_4w`: Número de emails de aplicantes con la misma fecha de nacimiento en las últimas 4 semanas -->

- `employment_status`: Estado de empleo del solicitante

- `credit_risk_score`: Score de riesgo de la aplicación

- `email_is_free`: Tipo del dominio del email del aplicante (email pago o gratis)

- `housing_status`: Estado residencial del aplicante

- `phone_home_valid`: Validez del telefono fijo provisto

- `phone_mobile_valid`: Validez del telefono movil provisto

<!-- - `bank_months_count`: Antiguedad de la cuenta anterior en meses -->

- `has_other_cards`: Indicadora de si la persona tiene otra tarjeta en el mismo banco

- `proposed_credit_limit`: Crédito limite propuesto por el aplicante

- `foreign_request`: Indicadora de si la solicitud fue hecha en el mismo pais que el banco

<!-- - `source`: Fuente online de la aplicación (Internet / app movil)  -->

<!-- - `session_length_in_minutes`: Tiempo de la sesión en la página del banco en minutos -->

- `device_os`: Sistema operativo del dispositivo que hizo la solicitud

- `keep_alive_session`: Indicadora de si el solicitante decidió mantener la sesión iniciada al ingresar

- `device_distinct_emails_8w`: Número de emails distintos en la página del banco desde el mismo dispositivo usado en las últimas 8 semanas

<!-- - `device_fraud_count`: Número de solicitudes fraudulentas desde el dispositivo utilizado  -->

<!-- - `month`: Mes en el que fue realizada la solicitud -->

\newpage

# Análisis descriptivo

```{r, include=FALSE}
library(ggplot2)
library(dplyr)
library(tidyr)
library(patchwork)
library(glmtoolbox)
library(statmod)
library(pROC)
library(ggforce)
library(caret)

theme_set(theme_bw() + 
            theme(plot.title = element_text(hjust = 0.5),
                  legend.position = "bottom"))

knitr::opts_chunk$set(fig.align = "center")

```


```{r}
data_og <- read.csv("Data/Base_resumida.csv") |> 
  mutate(
    income = factor(income),
    proposed_credit_limit_cat = case_when(proposed_credit_limit == 190 ~ 200,
                                          proposed_credit_limit == 200 ~ 200,
                                          proposed_credit_limit == 210 ~ 200,
                                          proposed_credit_limit == 490 ~ 500,
                                          proposed_credit_limit == 500 ~ 500,
                                          proposed_credit_limit == 510 ~ 500,
                                          proposed_credit_limit == 990 ~ 1000,
                                          proposed_credit_limit == 1000 ~ 1000,
                                          proposed_credit_limit == 1500 ~ 1500,
                                          proposed_credit_limit == 1900 ~ 2000,
                                          proposed_credit_limit == 2000 ~ 2000,
                                          T ~ 2000))

data_og <- data_og |> 
  mutate(
    fraud_bool = factor(fraud_bool),
    proposed_credit_limit_cat = factor(proposed_credit_limit_cat),
    has_other_cards = factor(has_other_cards),
    foreign_request = factor(foreign_request),
    phone_home_valid = factor(phone_home_valid),
    phone_mobile_valid = factor(phone_mobile_valid),
    email_is_free = factor(email_is_free),
    keep_alive_session = factor(keep_alive_session),
    current_address_months_count = case_when(current_address_months_count == -1 ~ NA,
                                              T ~ current_address_months_count),
    bank_months_count = case_when(bank_months_count == -1 ~ NA,
                                              T ~ bank_months_count),
    session_length_in_minutes = case_when(session_length_in_minutes == -1 ~ NA,
                                              T ~ session_length_in_minutes)
  ) |> 
  select(-prev_address_months_count,
         -zip_count_4w,
         -velocity_6h,
         -velocity_4w,
         -days_since_request,
         -intended_balcon_amount,
         -device_fraud_count,
         -bank_branch_count_8w,
         -date_of_birth_distinct_emails_4w)


# Creacion de muestra mas chica -----------------
set.seed(2024)

data_og <- drop_na(data = data_og)

fraude <- data_og |> filter(fraud_bool == 1)
fraude$n <- 1:nrow(fraude)

no_fraude <- data_og |> filter(fraud_bool == 0)
no_fraude$n <- 1:nrow(no_fraude)

proporcion <- sample(seq(0.1, 0.4, by = 0.05), size = 1)
n <- sample(400:700, size = 1)

sel_fraude <- sample(x = fraude$n, size = n*proporcion, replace = F)
sel_nofraude <- sample(x = no_fraude$n, size = n-(n*proporcion), replace = F)

fraude <- fraude[sel_fraude,]
no_fraude <- no_fraude[sel_nofraude,]

data <- rbind(fraude, no_fraude)


# Creacion datos de testeo -----------------

data_resto <- filter(data_og, !(X %in% data$X))

fraude <- data_resto |> filter(fraud_bool == 1)
fraude$n <- 1:nrow(fraude)

no_fraude <- data_resto |> filter(fraud_bool == 0)
no_fraude$n <- 1:nrow(no_fraude)

proporcion <- sample(seq(0.1, 0.4, by = 0.05), size = 1)
n <- floor(n*0.7)

sel_fraude <- sample(x = fraude$n, size = n*proporcion, replace = F)
sel_nofraude <- sample(x = no_fraude$n, size = n-(n*proporcion), replace = F)

fraude <- fraude[sel_fraude,]
no_fraude <- no_fraude[sel_nofraude,]

data_test <- rbind(fraude, no_fraude)


data_test <- data_test |> select(-n, -proposed_credit_limit, -X) |> 
  mutate(income_ord = as.numeric(income),
         proposed_credit_limit_cat_ord = as.numeric(proposed_credit_limit_cat),
         income = income_ord/10,
         proposed_credit_limit = case_when(proposed_credit_limit_cat_ord == 1 ~ 200,
                                          proposed_credit_limit_cat_ord == 2 ~ 500,
                                          proposed_credit_limit_cat_ord == 3 ~ 1000,
                                          proposed_credit_limit_cat_ord == 4 ~ 1500,
                                          T ~ 2000),
         housing_status = case_when(housing_status %in% c("BD", "BE", "BF") ~ "Otro",
                               T ~ housing_status),
    
          device_os = case_when(device_os == "x11" ~ "other",
                          T ~ device_os),
          customer_age = factor(case_when(customer_age %in% c(10,20) ~ "<20",
                             customer_age %in% c(60,70) ~ ">60",
                             T ~ as.character(customer_age))))




# Saco variables inutiles
data <- data |> select(-n, -proposed_credit_limit, -X)

```


```{r}
t1 <- data |> 
  group_by(fraud_bool) |> 
  summarise(n = n())

data |> 
  ggplot() +
  aes(x = fraud_bool, y = (after_stat(count))/sum(after_stat(count)))+
  geom_bar(color = "black", fill = c("#284B63", "#F15946")) +
  xlab(label = "Fraude") +
  ylab(label = "Proporción") +
  scale_y_continuous(limits = c(0,1)) +
  scale_x_discrete(labels = c("0" = "No", "1" = "Sí")) +
  geom_text(aes(label = after_stat(count), 
                y = after_stat(count)/sum(after_stat(count)) + 0.02), 
            stat = "count", 
            size = 5,
            vjust = 0)
```



```{r}
#| fig-cap: "Distribución del ingreso anual según si la transacción es fraudulenta o no"

((data |> 
  filter(fraud_bool == 0) |> 
  ggplot() +
  aes(x = as.numeric(income)/10, y = (after_stat(count))/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#284B63") +
  xlab(label = "Ingreso anual") +
  ylab(label = "Proporción") +
  scale_x_continuous(breaks = seq(0.1,0.9,0.1)) +
  scale_y_continuous(limits = c(0,0.8)) +
  ggtitle("No fraude")) +
(data |> 
   filter(fraud_bool == 1) |> 
   ggplot() +
   aes(x = as.numeric(income)/10, y = (after_stat(count))/sum(after_stat(count)))+
   geom_bar(color = "black", fill = "#F15946") +
   xlab(label = "Ingreso anual") +
   ylab(label = "Proporción") +
   scale_y_continuous(limits = c(0,0.8)) +
   scale_x_continuous(breaks = seq(0.1,0.9,0.1)) +
   ggtitle("Fraude"))) + plot_layout(axes = "collect")
```

Se puede observar que las personas que cometieron fraude tienden a tener un ingreso anual registrado mayor. La distribución tiene una mayor asimetría a la izquierda.


```{r}
#| fig-cap: "Distribución del índice de similitud entre en nombre del solicitante y el nombre en el email según si la transacción es fraudulenta o no"

(data |> 
   group_by(fraud_bool, device_distinct_emails_8w) |> 
   summarise(prop = n()) |> 
   mutate(prop = prop/sum(prop)) |> 
  ggplot() +
  aes(x = device_distinct_emails_8w, y = prop, fill = fraud_bool, group = fraud_bool)+
  geom_bar(color = "black", position = "dodge", stat = "identity") +
  xlab(label = "Número de emails distintos en la página del banco en las últimas 8 semanas") +
  ylab(label = "Proporción") +
  labs(fill = "Fraude") +
  scale_fill_manual(values = c("#284B63","#F15946"),labels = c("No","Si")) +
  scale_x_continuous(breaks = c(1,2)) +
  scale_y_continuous(limits = c(0,1)))
```

Las transacciones realizadas con emails no muy similares al nombre real de la persona parecen ser más propensas a ser fraudulentas. 



```{r}
#| fig-cap: "Proporción del tipo de pago según si la transacción es fraudulenta o no"

(data |> 
  filter(fraud_bool == 0) |> 
  ggplot() +
  aes(x = payment_type, y = (after_stat(count))/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#284B63") +
  xlab(label = "Tipo del plan de pago") +
  ylab(label = "Proporción") +
  scale_y_continuous(limits = c(0,0.8)) +
  ggtitle("No fraude") +
  geom_text(aes(label = after_stat(count), 
                y = after_stat(count)/sum(after_stat(count)) + 0.02), 
            stat = "count", 
            size = 5,
            vjust = 0)) +
(data |> 
  filter(fraud_bool == 1) |> 
  ggplot() +
  aes(x = payment_type, y = (after_stat(count))/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#F15946") +
  xlab(label = "Tipo del plan de pago") +
  ylab(label = "Proporción") +
  scale_y_continuous(limits = c(0,0.8)) +
  ggtitle("Fraude") +
  geom_text(aes(label = after_stat(count), 
                y = after_stat(count)/sum(after_stat(count)) + 0.02), 
            stat = "count", 
            size = 5,
            vjust = 0)) + plot_layout(axes = "collect")
```

En general, las personas que cometen fraude parecen preferir los métodos de pago "AB" y "AC" por encima del resto, al contrario de las personas que operan de manera legítima que prefieren de igual manera los tipos de pago "AA", "AB" y "AC". Se puede notar también que la forma de pago "AE" no es muy popular.


```{r}
#| fig-cap: "Distribución del límite crediticio propuesto por el solicitante según si la transacción es fraudulenta o no"

(data |> 
  filter(fraud_bool == 0) |> 
  ggplot() +
  aes(x = proposed_credit_limit_cat, y = after_stat(count)/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#284B63") +
  xlab(label = "Crédito límite propuesto") +
  ylab(label = "Proporción") +
  scale_y_continuous(limits = c(0,0.65))+
  ggtitle("No fraude")) +
(data |> 
  filter(fraud_bool == 1) |> 
  ggplot() +
  aes(x = proposed_credit_limit_cat, y = after_stat(count)/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#F15946") +
  xlab(label = "Crédito límite propuesto") +
  ylab(label = "Proporción") +
  scale_y_continuous(limits = c(0,0.65))+
  ggtitle("Fraude")) + plot_layout(axes = "collect")
```

Se puede destacar en este gráfico que las personas que cometen fraude son ligeramente más propensas a pedir créditos más altos.


```{r}
#| fig-cap: "Proporción de la tenencia de otra tarjeta en el mismo banco según si la transacción es fraudulenta o no"

(data |> 
   group_by(fraud_bool, has_other_cards) |> 
   summarise(prop = n()) |> 
   mutate(prop = prop/sum(prop)) |> 
  ggplot() +
  aes(x = has_other_cards, y = prop, fill = fraud_bool, group = fraud_bool)+
  geom_bar(color = "black", position = "dodge", stat = "identity") +
  xlab(label = "Tenencia de otras tarjetas") +
  ylab(label = "Proporción") +
  labs(fill = "Fraude") +
  scale_fill_manual(values = c("#284B63","#F15946"),labels = c("No","Si")) +
  scale_x_discrete(labels = c("0" = "No","1" = "Si")) +
  scale_y_continuous(limits = c(0,1)))
```

En cuanto a la tenencia de otra tarjeta en el mismo banco, suele ser común no poseer otra, sin embargo las personas que operan de forma legal se inclinan a tener más de una tarjeta un poco más que aquellos que cometen fraude.

```{r}
#| fig-cap: "Proporción del sistema operativo del dispositivo según si la transacción es fraudulenta o no"

(data |> 
  filter(fraud_bool == 0) |> 
  ggplot() +
  aes(x = device_os, y = after_stat(count)/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#284B63") +
  xlab(label = "Sistema operativo del dispositivo utilizado") +
  ylab(label = "Proporción") +
  geom_text(aes(label = after_stat(count), 
                y = after_stat(count)/sum(after_stat(count)) + 0.02), 
            stat = "count", 
            size = 5,
            vjust = 0) +
  scale_y_continuous(limits = c(0,0.65))+
  ggtitle("No fraude")) +
(data |> 
  filter(fraud_bool == 1) |> 
  ggplot() +
  aes(x = device_os, y = after_stat(count)/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#F15946") +
  xlab(label = "Sistema operativo del dispositivo utilizado") +
  ylab(label = "Proporción") +
  scale_y_continuous(limits = c(0,0.65))+
  ggtitle("Fraude") +
   geom_text(aes(label = after_stat(count), 
                y = after_stat(count)/sum(after_stat(count)) + 0.02), 
            stat = "count", 
            size = 5,
            vjust = 0)) + plot_layout(axes = "collect")
  
```


Se puede observar que las personas que cometen fraude, parecen utilizar Windows en mayor proporción que las personas que no cometen fraude. Dado que muy pocos clientes utilizan el sistema operativo "x11" se decidió agregarlo a la categoría "other".


```{r}
#| fig-cap: "Proporción del tipo de dominio del email según si la transacción es fraudulenta o no"

(data |> 
   group_by(fraud_bool, email_is_free) |> 
   summarise(prop = n()) |> 
   mutate(prop = prop/sum(prop)) |> 
  ggplot() +
  aes(x = email_is_free, y = prop, fill = fraud_bool, group = fraud_bool)+
  geom_bar(color = "black", position = "dodge", stat = "identity") +
  xlab(label = "Dominio del email") +
  ylab(label = "Proporción") +
  labs(fill = "Fraude") +
  scale_fill_manual(values = c("0" = "#284B63", "1" = "#F15946"),labels = c("No","Si")) +
  scale_x_discrete(labels = c("0" = "Pago","1" = "Gratuito")) +
  scale_y_continuous(limits = c(0,1)))
```

También se puede destacar que las operaciones fraudulentas parecen ser más comunes cuando el dominio del email del solicitante es gratuito que cuando es pago.

```{r}
#| fig-cap: "Estado residencial del cliente según si la transacción es fraudulenta o no"

(data |> 
  filter(fraud_bool == 0) |> 
  ggplot() +
  aes(x = housing_status, y = after_stat(count)/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#284B63") +
  xlab(label = "Estado residencial del cliente") +
  ylab(label = "Proporción") +
  geom_text(aes(label = after_stat(count), 
                y = after_stat(count)/sum(after_stat(count)) + 0.02), 
            stat = "count", 
            size = 5,
            vjust = 0) +
  scale_y_continuous(limits = c(0,0.65))+
  ggtitle("No fraude")) +
(data |> 
  filter(fraud_bool == 1) |> 
  ggplot() +
  aes(x = housing_status, y = after_stat(count)/sum(after_stat(count)))+
  geom_bar(color = "black", fill = "#F15946") +
  xlab(label = "Estado residencial del cliente") +
  ylab(label = "Proporción") +
  scale_y_continuous(limits = c(0,0.65))+
  ggtitle("Fraude") +
   geom_text(aes(label = after_stat(count), 
                y = after_stat(count)/sum(after_stat(count)) + 0.02), 
            stat = "count", 
            size = 5,
            vjust = 0)) + plot_layout(axes = "collect")
```


La distribución del score de riesgo para las personas que cometen fraude es simétrica y centrada alrededor de 200, mientras que la distribución del score de riesgo para las personas que no cometen fraude parece ser más asimétrica y tener una media menor. Dado que hay pocos datos en las categorías "BD", "BE" y "BF" se decidió agruparlas en una sola categoría llamada "Otros".




```{r}
#| fig-cap: "Proporción de opciones de inicio de sesión según si la transacción es fraudulenta o no"

(data |> 
   group_by(fraud_bool, keep_alive_session) |> 
   summarise(prop = n()) |> 
   mutate(prop = prop/sum(prop)) |> 
  ggplot() +
  aes(x = keep_alive_session, y = prop, fill = fraud_bool, group = fraud_bool)+
  geom_bar(color = "black", position = "dodge", stat = "identity") +
  xlab(label = "Mantener sesión abierta") +
  ylab(label = "Proporción") +
  labs(fill = "Fraude") +
  scale_fill_manual(values = c("0" = "#284B63", "1" = "#F15946"),labels = c("No","Si")) +
  scale_x_discrete(labels = c("0" = "No","1" = "Si")) +
  scale_y_continuous(limits = c(0,1)))

```


Por lo general, cuando las transacciones son fraudulentas la persona decide no mantener la sesión abierta en la cuenta del banco en mayor proporción que cuando las transacciones son legítimas.

# Modelado

Teniendo todo esto en cuenta se buscó un modelo que ajuste bien a los datos, para esto primero se realizó una selección de variables paso a paso, obteniendo el siguiente modelo:

```{r}
data <- data |> 
  mutate(
    housing_status = case_when(housing_status %in% c("BD", "BE", "BF") ~ "Otro",
                               T ~ housing_status),
    
    device_os = case_when(device_os == "x11" ~ "other",
                          T ~ device_os),
    customer_age = factor(case_when(customer_age %in% c(10,20) ~ "<20",
                             customer_age %in% c(60,70) ~ ">60",
                             T ~ as.character(customer_age)))
  )
# Modelado ---------------------

model <- glm(fraud_bool ~ ., data = data, family = binomial(link = "logit"), na.action = na.omit)

# step(model, direction = "both", trace=0)
# Customer age esta muy al limite asi que decidimos sacarla

modelo_logit <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit_cat + device_os + device_distinct_emails_8w, 
    data = data, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

# summary(modelo_logit)
```

$$
logit(\pi_i) = \beta_0 + \beta_I\cdot I_i + \beta_{H1}\cdot H_{1i} + \beta_{H2}\cdot H_{2i} + \beta_{H3}\cdot H_{3i} + \beta_{H4}\cdot H_{4i} + \beta_{H5}\cdot H_{5i} + \beta_{Ph}\cdot Ph_i +
$$
$$+ \beta_{Pm}\cdot Pm_i +  \beta_C\cdot C_i + \beta_L\cdot L_i + \beta_{D1}\cdot D_{1i} + \beta_{D2}\cdot D_{2i} + \beta_{D3}\cdot D_{3i} + \beta_{D4}\cdot D_{4i} + \beta_E\cdot E_i$$

Luego, al tener 2 variables continuas (ingreso y credito límite propuesto), se decidió comprobar la linealidad de estas. Para testear esto se implementó el test de razón de verosimilitud, en el que se compara el modelo que considera a la variable como ordinal (asignando scores) y el modelo que considera a la variable como categórica (asignando variables de diseño).

##### Ingreso

Para crear los modelos se tuvo que categorizar la variable ingreso en 4 categorías con aproximadamente la misma cantidad de observaciones. Las variables creadas son tales que:

| Ingreso    | I1 | I2 | I3 | S |
|------------|:--:|:--:|:--:|:-:|
| [0; 0.3]   |  0 |  0 |  0 | 1 |
| (0.3; 0.6] |  1 |  0 |  0 | 2 |
| (0.6; 0.8] |  0 |  1 |  0 | 3 |
| (0.8; 0.9] |  0 |  0 |  1 | 4 |

Modelo ordinal: 
$$
logit(\pi_i) = \beta_0 + \beta_I\cdot S_i + \beta_{H1}\cdot H_{1i} + \beta_{H2}\cdot H_{2i} + \beta_{H3}\cdot H_{3i} + \beta_{H4}\cdot H_{4i} + \beta_{H5}\cdot H_{5i} + \beta_{Ph}\cdot Ph_i +
$$
$$+ \beta_{Pm}\cdot Pm_i +  \beta_C\cdot C_i + \beta_L\cdot L_i + \beta_{D1}\cdot D_{1i} + \beta_{D2}\cdot D_{2i} + \beta_{D3}\cdot D_{3i} + \beta_{D4}\cdot D_{4i} + \beta_E\cdot E_i$$

Modelo categórico: 
$$
logit(\pi_i) = \beta_0 + \beta_{I_1}\cdot I_{1i} + \beta_{I_2}\cdot I_{2i} + \beta_{I_3}\cdot I_{3i} + \beta_{H1}\cdot H_{1i} + \beta_{H2}\cdot H_{2i} + \beta_{H3}\cdot H_{3i} + \beta_{H4}\cdot H_{4i} + \beta_{H5}\cdot H_{5i} + \beta_{Ph}\cdot Ph_i +
$$
$$+ \beta_{Pm}\cdot Pm_i +  \beta_C\cdot C_i + \beta_L\cdot L_i + \beta_{D1}\cdot D_{1i} + \beta_{D2}\cdot D_{2i} + \beta_{D3}\cdot D_{3i} + \beta_{D4}\cdot D_{4i} + \beta_E\cdot E_i$$

Hipótesis: $H_0)$ La variable es lineal \ \ vs \ \ $H_1)$ La variable no es lineal

Estadística: $G^2 = -2(Ln(L_{ord}) - Ln(L_{cat})) \underset{H_0}{\sim} \chi^2_{2}$

Dado que el valor p resulta igual a $0.6906$ no se rechaza la hipótesis nula y por lo tanto se introduce la variable al modelo como lineal.

##### Crédito límite propuesto

Nuevamente, para realizar el test se tuvo que crear variables de diseño y de scores, las cuales son:

| Límite cred. propuesto | L1 | L2 | L3 | L4 | S |
|:----------------------:|:--:|:--:|:--:|:--:|:-:|
| [0; 200]               |  0 |  0 |  0 |  0 | 1 |
| (200; 500]             |  1 |  0 |  0 |  0 | 2 |
| (500; 1000]            |  0 |  1 |  0 |  0 | 3 |
| (1000; 1500]           |  0 |  0 |  1 |  0 | 4 |
| (1500; 2000]           |  0 |  0 |  0 |  1 | 5 |

Modelo ordinal: 
$$
logit(\pi_i) = \beta_0 + \beta_I\cdot I_i + \beta_{H1}\cdot H_{1i} + \beta_{H2}\cdot H_{2i} + \beta_{H3}\cdot H_{3i} + \beta_{H4}\cdot H_{4i} + \beta_{H5}\cdot H_{5i} + \beta_{Ph}\cdot Ph_i +
$$
$$+ \beta_{Pm}\cdot Pm_i +  \beta_C\cdot C_i + \beta_L\cdot S_i + \beta_{D1}\cdot D_{1i} + \beta_{D2}\cdot D_{2i} + \beta_{D3}\cdot D_{3i} + \beta_{D4}\cdot D_{4i} + \beta_E\cdot E_i$$

Modelo categórico: 
$$
logit(\pi_i) = \beta_0 + \beta_{I_1}\cdot I_{i} + \beta_{H1}\cdot H_{1i} + \beta_{H2}\cdot H_{2i} + \beta_{H3}\cdot H_{3i} + \beta_{H4}\cdot H_{4i} + \beta_{H5}\cdot H_{5i} + \beta_{Ph}\cdot Ph_i +
$$
$$+ \beta_{Pm}\cdot Pm_i +  \beta_C\cdot C_i + \beta_{L_1}\cdot L_{1i}+ \beta_{L_2}\cdot L_{2i} + \beta_{L_3}\cdot L_{3i} + \beta_{L_4}\cdot L_{4i} + \beta_{D1}\cdot D_{1i} + \beta_{D2}\cdot D_{2i} + \beta_{D3}\cdot D_{3i} + \beta_{D4}\cdot D_{4i} + \beta_E\cdot E_i$$

Hipótesis: $H_0)$ La variable es lineal \ \ vs \ \ $H_1)$ La variable no es lineal

Estadística: $G^2 = -2(Ln(L_{ord}) - Ln(L_{cat})) \underset{H_0}{\sim} \chi^2_{2}$

Dado que el valor p resulta igual a $0.1578$ no se rechaza la hipótesis nula y por lo tanto se introduce la variable al modelo como lineal.

```{r}

# Linealidad de las variables ordinales 

data_linealidad <- data |> 
  mutate(
    income = as.numeric(income)/10,
    income_dummie = factor(case_when(income <= 0.3 ~ "hasta0.3",
                           income <= 0.6 ~ "hasta0.6",
                           income <= 0.8 ~ "hasta0.8",
                           T ~ "0.9"
                           )),
    income_ord = factor(case_when(income/10 <= 0.3 ~ "hasta0.3",
                           income <= 0.6 ~ "hasta0.6",
                           income <= 0.8 ~ "hasta0.8",
                           T ~ "0.9"
                           ), levels = c("hasta0.3", "hasta0.6", "hasta0.8", "0.9")),
    income_ord_2 = cut(as.numeric(income), breaks = c(-Inf,0.3,0.6,0.8,Inf), labels = F),
    proposed_credit_limit_cat_ord = as.numeric(proposed_credit_limit_cat)
  )

model_income_ord <- glm(fraud_bool ~ income_ord_2 + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit_cat + device_os + device_distinct_emails_8w, 
    data = data_linealidad, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

model_income_dummie <- glm(fraud_bool ~ income_dummie + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit_cat + device_os + device_distinct_emails_8w, 
    data = data_linealidad, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

linealidad <- anova(model_income_ord, model_income_dummie)

# pchisq(0.74044, 2,lower.tail = F) = 0.6905824

# No rechazo H0 por lo que la variable ingreso es lineal

model_cardlimit_ord <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit_cat_ord + device_os + device_distinct_emails_8w, 
    data = data_linealidad, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

model_cardlimit_cat <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit_cat + device_os + device_distinct_emails_8w, 
    data = data_linealidad, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

linealidad <- anova(model_cardlimit_ord, model_cardlimit_cat)

# pchisq(5.1985, 3,lower.tail = F)

# No se rechaza h0 por lo que la variable es lineaaaaal

data <- data |>
  mutate(
    income = as.numeric(income)/10,
    proposed_credit_limit_cat_ord = as.numeric(proposed_credit_limit_cat),
    proposed_credit_limit = case_when(proposed_credit_limit_cat_ord == 1 ~ 200,
                                          proposed_credit_limit_cat_ord == 2 ~ 500,
                                          proposed_credit_limit_cat_ord == 3 ~ 1000,
                                          proposed_credit_limit_cat_ord == 4 ~ 1500,
                                          T ~ 2000)
  )

```

```{r}
# Nuevo modelo ajustado con ls variables ordinales

modelo_logit <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w, 
    data = data, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

# summary(modelo_logit)

```

Además, se propusieron ciertas interacciones, más precisamente la interacción entre la validez del número de teléfono móvil brindado y la tenencia de otra tarjeta en el banco, y entre la validez del número de teléfono móvil brindado y el ingreso. Si bien estas resultaron significativas al realizar el test de razón de verosimilitud, al ya contar con muchas variables se decidió no incluirlas para no complejizar el modelo y su interpretabilidad. Sin embargo este modelo será utilizado más adelante como motivo de comparación con el modelo ajustado.


```{r}

# Prueba de interacciones dobles de interés

modelo_logit_1 <- glm(fraud_bool ~ income + housing_status +
    phone_home_valid + phone_mobile_valid + has_other_cards +
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:has_other_cards,
    data = data,
    family = binomial(link = "logit"),
    na.action = na.omit)

# summary(modelo_logit_1)
# anova(modelo_logit, modelo_logit_1)
# pchisq(3.9032, 1, lower.tail = F)


modelo_logit_2 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:phone_mobile_valid, 
    data = data, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

# anova(modelo_logit, modelo_logit_2)



modelo_logit_3 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:phone_mobile_valid + has_other_cards:phone_mobile_valid, 
    data = data, 
    family = binomial(link = "logit"), 
    na.action = na.omit)

# anova(modelo_logit_2, modelo_logit_3)

# summary(modelo_logit_2)
```


<!-- $$ -->
<!-- logit(\pi_i) = \beta_0 + \beta_I\cdot I_i + \beta_{H1}\cdot H_{1i} + \beta_{H2}\cdot H_{2i} + \beta_{H3}\cdot H_{3i} + \beta_{H4}\cdot H_{4i} + \beta_{H5}\cdot H_{5i} + \beta_{Ph}\cdot Ph_i + \beta_{Pm}\cdot Pm_i + \beta_C\cdot C_i + \beta_L\cdot L_i + \beta_D\cdot D_i + \beta_E\cdot E_i + \beta_{IPm}\cdot I_i\cdot Pm_i + \beta_{CPm}\cdot C_i\cdot Pm_i  -->
<!-- $$ -->

Una vez definida la componente lineal se decidió comprobar el enlace:

```{r Comprobacion del enlace modelo con interaccion, eval=FALSE}
data_enlaces <- data

# Comprobacion enlace logit --------------------
pred.logit<-predict(modelo_logit_3)
data_enlaces$pred.2.logit <- pred.logit*pred.logit

modelo_logit.2 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:phone_mobile_valid + has_other_cards:phone_mobile_valid + pred.2.logit,
    data = data_enlaces,
    family = binomial(link = "logit"),
    na.action = na.omit)


# anova(modelo_logit_3, modelo_logit.2, test="LRT")

# Este enlace es apropiado

# Comprobacion enlace probit --------------------
modelo_probit <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:phone_mobile_valid + has_other_cards:phone_mobile_valid, data = data, family = binomial(link = "probit"), na.action = na.omit)

pred.probit <- predict(modelo_probit)
data_enlaces$pred.2.probit <- pred.probit*pred.probit

modelo_probit.2 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:phone_mobile_valid + has_other_cards:phone_mobile_valid + pred.2.probit,
    data = data_enlaces,
    family = binomial(link = "probit"),
    na.action = na.omit)

# anova(modelo_probit, modelo_probit.2, test="LRT")

# Este enlace es apropiado


# Comprobacion enlace cloglog --------------------
modelo_cloglog <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:phone_mobile_valid + has_other_cards:phone_mobile_valid, data = data, family = binomial(link = "cloglog"), na.action = na.omit)

pred.cloglog <- predict(modelo_cloglog)
data_enlaces$pred.2.cloglog <- pred.cloglog*pred.cloglog

modelo_cloglog.2 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + income:phone_mobile_valid + has_other_cards:phone_mobile_valid +  pred.2.cloglog,
    data = data_enlaces,
    family = binomial(link = "cloglog"),
    na.action = na.omit)

# anova(modelo_cloglog, modelo_cloglog.2, test="LRT")

# Este enlace es apropiado

```


```{r comrpobacion del enlace modelo sin interaccion}
data_enlaces <- data

# Comprobacion enlace logit --------------------
pred.logit<-predict(modelo_logit)
data_enlaces$pred.2.logit <- pred.logit*pred.logit

modelo_logit.2 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + pred.2.logit,
    data = data_enlaces,
    family = binomial(link = "logit"),
    na.action = na.omit)


# anova(modelo_logit, modelo_logit.2, test="LRT")

# Este enlace es apropiado

# Comprobacion enlace probit --------------------
modelo_probit <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w,
    data = data, family = binomial(link = "probit"), na.action = na.omit)

pred.probit <- predict(modelo_probit)
data_enlaces$pred.2.probit <- pred.probit*pred.probit

modelo_probit.2 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + pred.2.probit,
    data = data_enlaces,
    family = binomial(link = "probit"),
    na.action = na.omit)

# anova(modelo_probit, modelo_probit.2, test="LRT")

# Este enlace es apropiado


# Comprobacion enlace cloglog --------------------
modelo_cloglog <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w,
    data = data, family = binomial(link = "cloglog"), na.action = na.omit)

pred.cloglog <- predict(modelo_cloglog)
data_enlaces$pred.2.cloglog <- pred.cloglog*pred.cloglog

modelo_cloglog.2 <- glm(fraud_bool ~ income + housing_status + 
    phone_home_valid + phone_mobile_valid + has_other_cards + 
    proposed_credit_limit + device_os + device_distinct_emails_8w + pred.2.cloglog,
    data = data_enlaces,
    family = binomial(link = "cloglog"),
    na.action = na.omit)

# anova(modelo_cloglog, modelo_cloglog.2, test="LRT")

# Este enlace es apropiado

```


|   Enlace  | Estadistica test RV | Grados de libertad test RV | Valor p test RV | Estadistica test H-L | Grados de libertad test H-L | Valor p  test H-L |
|:---------:|:-------------------:|:--------------------------:|:---------------:|:--------------------:|:---------------------------:|:-----------------:|
| Logístico |        0.8010       |              1             |      0.3708     |        2.7342        |              8              |       0.9499      |
|   Probit  |        1.9706       |              1             |      0.1604     |        5.7644        |              8              |       0.6736      |
|  Cloglog  |        0.0015       |              1             |      0.9682     |        2.6860        |              8              |       0.9525      |

:Test de comprobación de la función de enlace y bondad del ajuste

Los tres enlaces son apropiados, por lo tanto nos quedamos con el enlace logit por su facilidad en la interpretación.

```{r Test hosmer y lemeshow}
# hltest(modelo_logit_3)
# hltest(modelo_logit)
# hltest(modelo_probit)
# hltest(modelo_cloglog)
```

### Modelo estimado

$$
logit(\pi_i) = \hat\beta_0 + \hat\beta_I\cdot I_i + \hat\beta_{H1}\cdot H_{1i} + \hat\beta_{H2}\cdot H_{2i} + \hat\beta_{H3}\cdot H_{3i} + \hat\beta_{Ph}\cdot Ph_i +$$
$$+ \hat\beta_{Pm}\cdot Pm_i + \hat\beta_C\cdot C_i + \hat\beta_L\cdot L_i + \hat\beta_{D1}\cdot D_{1i} + \hat\beta_{D2}\cdot D_{2i} + \hat\beta_{D3}\cdot D_{3i} + \hat\beta_E\cdot E_i$$

```{r, eval=TRUE}

# x <- summary(modelo_logit_3)
x <- summary(modelo_logit)

# tabla1 <- data.frame(Efecto = c("Intercepto", "Ingreso", "Estado residencial:BB",
#                       "Estado residencial:BC", "Estado residencial:BD",
#                       "Estado residencial:BE","Estado residencial:BF",
#                       "Teléfono Fijo:Válido","Teléfono Móvil:Válido"),
#            Coeficiente = modelo_logit_3$coefficients[1:9],row.names = NULL,
#            LI = modelo_logit_3$coefficients[1:9] - x$coefficients[1:9,2]*1.96, 
#            LS = modelo_logit_3$coefficients[1:9] + x$coefficients[1:9,2]*1.96
#            )
# 
# tabla2 <- data.frame(Efecto = c("Otra tarjeta:Si", "Límite propuesto", "Sistema Operativo:MacOS", "Sistema Operativo:Otro", "Sistema Operativo:Windows", "Sistema Operativo:OSx11", "N° de Emails Distintos_8w","Ingreso::Teléfono Móvil:Válido", "Otra tarjeta:Si::Teléfono Móvil:Válido"),
#            Coeficiente = modelo_logit_3$coefficients[10:18],row.names = NULL,
#            LI = modelo_logit_3$coefficients[10:18] - x$coefficients[10:18,2]*1.96, 
#            LS = modelo_logit_3$coefficients[10:18] + x$coefficients[10:18,2]*1.96
#            )



tabla1 <- data.frame(Beta = c("$\\hat\\beta_0$","$\\hat\\beta_{I}$", "$\\hat\\beta_{H1}$", "$\\hat\\beta_{H2}$", "$\\hat\\beta_{H3}$", "$\\hat\\beta_{Ph}$", "$\\hat\\beta_{Pm}$"),
                     Efecto = c("Intercepto", "Ingreso", "Estado residencial:BB",
                      "Estado residencial:BC", "Estado residencial:Otros",
                      "Teléfono fijo:Válido", "Teléfono móvil:Válido"),
           Coeficiente = modelo_logit$coefficients[1:7],row.names = NULL,
           LI = modelo_logit$coefficients[1:7] - x$coefficients[1:7,2]*1.96, 
           LS = modelo_logit$coefficients[1:7] + x$coefficients[1:7,2]*1.96
           )

tabla2 <- data.frame(Beta = c("$\\hat\\beta_{C}$", "$\\hat\\beta_{L}$", "$\\hat\\beta_{D1}$", "$\\hat\\beta_{D2}$", "$\\hat\\beta_{D3}$", "$\\hat\\beta_{E}$"),
                     Efecto = c("Otra tarjeta:Si", "Crédito límite propuesto", "Sistema operativo:MacOS", "Sistema operativo:Otro", "Sistema operativo:Windows", "N° de emails distintos (8 sem)"),
           Coeficiente = modelo_logit$coefficients[8:13],row.names = NULL,
           LI = modelo_logit$coefficients[8:13] - x$coefficients[8:13,2]*1.96, 
           LS = modelo_logit$coefficients[8:13] + x$coefficients[8:13,2]*1.96
           )

```


```{r}
#| tbl-cap: "Coesficientes estimados del modelo ajustado"

knitr::kable(rbind(tabla1, tabla2), digits = 3)
```

<!-- ### Interpretacion de los coeficientes del modelo -->

<!-- -   $\beta_0$: La log chance de que el cliente cometa fraude cuando las variables cuantitativas valen 0, y las cualitativas se ubican en su categoría de referencia. -->
<!-- -   $\beta_I$: El cambio esperado en la log chance por aumento unitario de la variable ingreso. -->
<!-- -   $\hat\beta_{0}=-10.48$ -->
<!-- -   $\hat\beta_{I}=8.03$ -->
<!-- -   $\hat\beta_{H1}=-1.05$ -->
<!-- -   $\hat\beta_{H2}=-1.62$ -->
<!-- -   $\hat\beta_{H3}=-17.52$ -->
<!-- -   $\hat\beta_{H4}=-2.5$ -->
<!-- -   $\hat\beta_{H5}=-17.16$ -->
<!-- -   $\hat\beta_{Ph}=-1.31$ -->
<!-- -   $\hat\beta_{Pm}=3.21$ -->
<!-- -   $\hat\beta_{C}=-18.56$ -->
<!-- -   $\hat\beta_{L}=0.001$ -->
<!-- -   $\hat\beta_{D1}=1.15$ -->
<!-- -   $\hat\beta_{D2}=-1.02$ -->
<!-- -   $\hat\beta_{D3}=0.75$ -->
<!-- -   $\hat\beta_{D4}=-16.42$ -->
<!-- -   $\hat\beta_{E}=4.55$ -->
<!-- -   $\hat\beta_{IPm}=-5.99$ -->
<!-- -   $\hat\beta_{CPm}=17.84$ -->




## Analisis de residuos

### Evaluación de la componente sistemática


```{r analisis de residuos modelo con interacciones, eval=FALSE}
#| fig-cap: "Gráfico de residuos cuantil vs. las probabilidades estimadas"

# Residuos cuantil
rQ.logit <- qresid(modelo_logit_3)

# Mu estimado
mu_logit <- fitted(modelo_logit_3)

### Gráfico de residuos cuantil vs. probabilidades estimadas (ajuste logit)
G1 <- ggplot(data_enlaces, aes(y = rQ.logit, x = fitted(modelo_logit_3))) + 
  geom_point(fill = "orange", shape = 21, size = 3, alpha = 0.4) +
  geom_hline(yintercept = 0) + 
  # ylim(-3, 3) + 
  geom_hline(yintercept = -3, linetype = "dashed") + 
  geom_hline(yintercept =  3, linetype = "dashed") +
  labs(title = "Gráfico de residuos cuantil vs. las probabilidades estimadas", x = expression(hat(pi)), y = "Residuos cuantil") +
  theme_minimal()

# ### Gráfico de residuos cuantil vs. la media estimada (ajuste logit)
# G2 <- ggplot(data_enlaces, aes(y = rQ.logit, x = mu_logit)) + 
#   geom_point(fill = "orange", shape = 21, size = 3, alpha = 0.4) +
#   geom_hline(yintercept = 0) + 
#   # ylim(-3, 3) + 
#   geom_hline(yintercept = -3, linetype = "dashed") + 
#   geom_hline(yintercept =  3, linetype = "dashed") +
#   labs(title = "Gráfico de residuos cuantil vs. las medias estimadas", x = expression(hat(mu)), y = "Residuos cuantil") +
#   theme_minimal()

# G1+G2
G1
```


```{r analisis de residuos modelo sin interacciones}
#| fig-cap: "Gráfico de residuos cuantil vs. las probabilidades estimadas"

# Residuos cuantil
rQ.logit <- qresid(modelo_logit)

# Mu estimado
mu_logit <- fitted(modelo_logit)

### Gráfico de residuos cuantil vs. probabilidades estimadas (ajuste logit)
G1 <- ggplot(data_enlaces, aes(y = rQ.logit, x = fitted(modelo_logit))) + 
  geom_point(fill = "orange", shape = 21, size = 3, alpha = 0.4) +
  geom_hline(yintercept = 0) + 
  # ylim(-3, 3) + 
  geom_hline(yintercept = -3, linetype = "dashed") + 
  geom_hline(yintercept =  3, linetype = "dashed") +
  labs(x = expression(hat(pi)), y = "Residuos cuantil") +
  theme_minimal()

G1
```

Dado que no se ve ningún patrón y ningun punto se escapa de las bandas se puede decir que la componente sistematica seleccionada es adecuada.

### Comprobación de la distribución propuesta

```{r}
#| fig-cap: "Gráfico probabilístico normal con residuos cuantil"

# Gráfico QQ
ggplot(data_enlaces, aes(sample = rQ.logit)) +
  stat_qq(distribution = qnorm, fill = "orange", shape = 21, size = 3, alpha = 0.4) +
  stat_qq_line() +
  annotate(geom = "label", label = paste("Test de Normalidad Shapiro-Wilks\n p-value:", round(shapiro.test(rQ.logit)$p.value, 2)), x = 0.9, y = -1.5, fill = "lightblue1") +
  labs(x = "Cuantiles teóricos", y = "Cuantiles de los residuos cuantil") +
  theme_minimal()


```

Viendo el gráfico y el test de Shapiro-Wilks para la normalidad de los errores, se puede concluir que la elección de la distribución de la variable es correcta.


# Interpretaciones


```{r RO modelo con interacciones, eval=FALSE}
data.frame(
  RO = c(
    "Límite propuesto()",
    "Teléfono fijo:Válido",
    "Ingreso(Teléfono Móvil:Válido)",
    "Ingreso(Teléfono Móvil:No Válido)",
    "Otra tarjeta:Si(Teléfono Móvil:Válido)",
    "Otra tarjeta:Si(Teléfono Móvil:No Válido)"
  ),
  Estimacion = c(exp(0.0010984*100), # Cada 100 unidades
                 exp(-1.3103827),
                 exp(0.1*(8.0253869-5.9870999)), # Cada 0.1 unidades
                 exp(0.1*8.0253869),
                 exp(-18.5564241 + 17.8351852),
                 exp(-18.5564241)),
  LI = c(
    exp(0.0010984*100 - 1.96 * 100 * sqrt(x$cov.unscaled["proposed_credit_limit","proposed_credit_limit"])),
    exp(-1.3103827 - 1.96 * sqrt(x$cov.unscaled["phone_home_valid1","phone_home_valid1"])),
    exp(0.1*(8.0253869-5.9870999) - 
          1.96 * (sqrt(0.1**2 * x$cov.unscaled["income","income"] + x$cov.unscaled["phone_mobile_valid1","phone_mobile_valid1"] + 2 * 0.1 * x$cov.unscaled["phone_mobile_valid1","income"]))),
    exp(0.1*8.0253869 - 1.96 * sqrt(x$cov.unscaled["income","income"])),
    exp((-18.5564241 + 17.8351852) - 
          1.96 * (sqrt(x$cov.unscaled["has_other_cards1","has_other_cards1"] + x$cov.unscaled["phone_mobile_valid1","phone_mobile_valid1"] + 2 * x$cov.unscaled["phone_mobile_valid1","has_other_cards1"]))),
    exp(-18.5564241 - 1.96 * sqrt(x$cov.unscaled["has_other_cards1","has_other_cards1"]))
    ),
  LS = c(
    exp(0.0010984*100 + 1.96 * 100 * sqrt(x$cov.unscaled["proposed_credit_limit","proposed_credit_limit"])),
    exp(-1.3103827 + 1.96 * sqrt(x$cov.unscaled["phone_home_valid1","phone_home_valid1"])),
    exp(0.1*(8.0253869-5.9870999) + 
          1.96 * (sqrt(0.1**2 * x$cov.unscaled["income","income"] + x$cov.unscaled["phone_mobile_valid1","phone_mobile_valid1"] + 2 * 0.1 * x$cov.unscaled["phone_mobile_valid1","income"]))),
    exp(0.1*8.0253869 + 1.96 * sqrt(x$cov.unscaled["income","income"])),
    exp((-18.5564241 + 17.8351852) + 
          1.96 * (sqrt(x$cov.unscaled["has_other_cards1","has_other_cards1"] + x$cov.unscaled["phone_mobile_valid1","phone_mobile_valid1"] + 2 * x$cov.unscaled["phone_mobile_valid1","has_other_cards1"]))),
    exp(-18.5564241 + 1.96 * sqrt(x$cov.unscaled["has_other_cards1","has_other_cards1"]))
    )
  
)
```


```{r RO modelo sin interacciones}
#| tbl-cap: "Razones de odds del modelo ajustado"

tabla_ro <- data.frame(
  RO = c(
    "Límite propuesto",
    "Teléfono fijo:Válido",
    "Ingreso",
    "Tenencia otra tarjeta"
  ),
  Estimacion = c(
                 exp(as.numeric(modelo_logit$coefficients["proposed_credit_limit"])*100),
                 exp(as.numeric(modelo_logit$coefficients["phone_home_valid1"])),
                 exp(as.numeric(modelo_logit$coefficients["income"])*0.1),
                 exp(as.numeric(modelo_logit$coefficients["has_other_cards1"]))
                 ),
  LI = c(
    exp(as.numeric(modelo_logit$coefficients["proposed_credit_limit"])*100 - 1.96 * 100 * x$coefficients["proposed_credit_limit",2]),
    exp(as.numeric(modelo_logit$coefficients["phone_home_valid1"]) - 1.96 * x$coefficients["phone_home_valid1",2]),
    exp(as.numeric(modelo_logit$coefficients["income"])*0.1 - 1.96 * 0.1 * x$coefficients["income",2]),
    exp(as.numeric(modelo_logit$coefficients["has_other_cards1"]) - 1.96 * x$coefficients["has_other_cards1",2])
    ),
  LS = c(
    exp(as.numeric(modelo_logit$coefficients["proposed_credit_limit"])*100 + 1.96 * 100 * x$coefficients["proposed_credit_limit",2]),
    exp(as.numeric(modelo_logit$coefficients["phone_home_valid1"]) + 1.96 * x$coefficients["phone_home_valid1",2]),
    exp(as.numeric(modelo_logit$coefficients["income"])*0.1 + 1.96 * 0.1 * x$coefficients["income",2]),
    exp(as.numeric(modelo_logit$coefficients["has_other_cards1"]) + 1.96 * x$coefficients["has_other_cards1",2])
    )
  
)

knitr::kable(tabla_ro, digits = 4)
```

La chance de que un cliente cometa fraude aumenta entre un 5% y un 18% cuando el límite del crédito propuesto aumenta en 100 unidades monetarias, cuando las demás variables son constantes.

A su vez, cuando el cliente proporciona un telefono fijo válido, la chance de que este cometa fraude es como mínimo un 41% y como máximo un 88% menor que la de una persona que no proporcionó un telefono fijo válido, cuando el resto de las variables son constantes.

Cuando el ingreso del cliente aumenta en un decil, la chance de que cometa fraude aumenta entre un 12% y un 50%, cuando las variables son constantes.

Los clientes que tienen otra tarjeta en el mismo banco tienen una chance de cometer fraude entre un 14% y un 86% menor que aquellos que no tienen, cuando el resto de las variables son constantes.

Las características de las personas más propensas a cometer fraude son:

- Ingreso alto

- Estado residencial del aplicante "BA"

- Número de teléfono fijo proporcionado no válido

- Número de celular proporcionado no válido

- No posee otra tarjeta en el mismo banco

- Límite del crédito propuesto alto

- Sistema operativo usado macOS

- 2 emails registrados en la página del banco en las últimas 8 semanas


Las características de las personas menos propensas a cometer fraude son:

- Ingreso Bajo

- Estado residencial del aplicante otro (distinto de "BA", "BB", "BC")

- Número de teléfono fijo proporcionado válido

- Número de celular proporcionado válido

- Posee otra tarjeta en el mismo banco

- Límite del crédito propuesto bajo

- Sistema operativo usado otros (distintos de Windows, macos y Linux)

- Un solo email registrado en la página del banco en las últimas 8 semanas



# Capacidad predictiva

```{r}
#| fig-cap: "Curva ROC del modelo ajustado"

curva_roc_knn <- roc(response = data$fraud_bool, predictor = fitted(modelo_logit), plot = F)

best_knn <- coords(curva_roc_knn, "local maximas")[7,]

data.frame(especificidad = curva_roc_knn$specificities,
           sensibilidad = curva_roc_knn$sensitivities,
           punto_corte = curva_roc_knn$thresholds
          ) |> 
  arrange(especificidad, sensibilidad) |> 
  ggplot() +
  geom_line(aes(x = especificidad, y = sensibilidad)) +
  scale_x_reverse() +
  geom_segment(x = -1, xend=0, y = 0, yend = 1) +
  annotate(x = 0.8, y = 0.4, geom = "text", label = paste("AUC =", round(curva_roc_knn$auc, digits = 4))) +
  geom_mark_ellipse(
    aes(x = best_knn$specificity, y = best_knn$sensitivity,
      label = format(round(as.numeric(best_knn$threshold), digits = 6), scientific = F),
      description = "Punto de corte"), 
    color = "red", 
    expand = 0.01) + 
  labs(x = "Especificidad", y = "Sensibilidad")

```

Se decidió elegir el mejor punto de corte como aquel que maximiza la especificidad (probabilidad de que un no fraude sea clasificado como tal) garantizando una sensibilidad (probabilidad de que un fraude sea clasificado como tal) de al menos un 90%, esto para evitar el máximo número de fraudes posibles sin afectar a los clientes legítimos.

```{r capacidad predictiva modelo sin interaccion}
prob_pred <- exp(predict(modelo_logit, newdata = data_test))/(1+exp(predict(modelo_logit, newdata = data_test)))

fraud_pred <- factor(ifelse(prob_pred >= best_knn$threshold, 1, 0), levels = c(0,1))

# confusionMatrix(fraud_pred, reference = data_test$fraud_bool, positive = "1")

matriz_confucion <- confusionMatrix(fraud_pred, reference = data_test$fraud_bool, positive = "1")
```


```{r capacidad predictiva modelo sin interaccion 2}
#| fig-cap: "Matriz de confusión del modelo ajustado ante nuevos clientes"

data.frame(matriz_confucion$table) |> 
  mutate(Prediction = case_when(Prediction == 0 ~ "No fraude",
                                T ~ "Fraude"),
         Reference = case_when(Reference == 0 ~ "No fraude",
                                T ~ "Fraude")) |> 
  ggplot() +
  aes(x = Prediction, y = Reference, fill = Freq, label = Freq) +
  geom_tile(color = "black") +
  geom_label() +
  scale_fill_gradient(low = "#cfeac8", high = "#4db146") +
  labs(x = "Valor Predicho", y = "Valor Observado",
       caption = paste0("Precisión: ", round(matriz_confucion$overall[1], 2), "        |        ",
                        "Sensibilidad: ", round(matriz_confucion$byClass[1], 2), "        |        ",
                        "Especificidad: ", round(matriz_confucion$byClass[2], 2) 
                        )) +
  theme_bw() + 
  theme(legend.position = "none",
        plot.caption = element_text(hjust=0.5,size = 10))
```

Además, se quiso evaluar la capacidad predictiva del mismo modelo agregando las 2 interacciones significativas mencionadas en el ajuste del modelo:

```{r capacidad predictiva modelo con interaccion}

#| fig-cap: "Matriz de confusión del modelo con interacciones ante nuevos clientes"

curva_roc_knn <- roc(response = data$fraud_bool, predictor = fitted(modelo_logit_3), plot = F)

best_knn <- coords(curva_roc_knn, "local maximas")[7,]

prob_pred <- exp(predict(modelo_logit_3, newdata = data_test))/(1+exp(predict(modelo_logit_3, newdata = data_test)))

fraud_pred <- factor(ifelse(prob_pred >= best_knn$threshold, 1, 0), levels = c(0,1))

matriz_confucion <- confusionMatrix(fraud_pred, reference = data_test$fraud_bool, positive = "1")


data.frame(matriz_confucion$table) |> 
  mutate(Prediction = case_when(Prediction == 0 ~ "No fraude",
                                T ~ "Fraude"),
         Reference = case_when(Reference == 0 ~ "No fraude",
                                T ~ "Fraude")) |> 
  ggplot() +
  aes(x = Prediction, y = Reference, fill = Freq, label = Freq) +
  geom_tile(color = "black") +
  geom_label() +
  scale_fill_gradient(low = "#cfeac8", high = "#4db146") +
  labs(x = "Valor Predicho", y = "Valor Observado",
       caption = paste0("Precisión: ", round(matriz_confucion$overall[1], 2), "        |        ",
                        "Sensibilidad: ", round(matriz_confucion$byClass[1], 2), "        |        ",
                        "Especificidad: ", round(matriz_confucion$byClass[2], 2) 
                        )) +
  theme_bw() + 
  theme(legend.position = "none",
        plot.caption = element_text(hjust=0.5,size = 11))
```

Observando las matrices de confusión y las métricas de comparación, haciendo énfasis en la sensibilidad, se puede notar que el modelo de efectos principales tiene una mejor capacidad preditiva en base al objetivo propuesto que el modelo que tiene 2 efectos más. Esto puede adjudicarse al sobreajuste que el modelo tiene sobre los datos que se usaron como entrenamiento, ya que si bien un modelo con muchos efectos va a predecir mejor sobre los datos que modela, ante nuevos datos el ajuste no será tan bueno.



# Checkear la cantidad de dummies en los modelos